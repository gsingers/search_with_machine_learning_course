{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0834be6a-ba57-4bcf-8066-d1d35bc59a25",
   "metadata": {},
   "source": [
    "# Classifying Product Names into Cateogories"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c7a6c7-2d2a-4174-a823-63dc6483d0b6",
   "metadata": {},
   "source": [
    "## 0. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97d64d55-077d-437c-979b-c03b64f73856",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastcore.foundation import L\n",
    "from fastcore.test import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dbcec7ef-4c23-4264-a036-a0f0968fd646",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext as ft"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018b0d8f-3bcf-4d46-bcbf-0f0af09531e1",
   "metadata": {},
   "source": [
    "Data Prerequisite:\n",
    "    `gunzip /workspace/search_with_machine_learning_course/data/*/*.xml.gz`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d3d75a0-8a92-4c32-9ce3-5827739dff6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_res(res, k=1): \n",
    "    print(f\"N\\t: {res[0]} \\nP@{k}\\t: {res[1]:.3f} \\nR@{k}\\t: {res[2]:.3f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "220906aa-330a-4af0-9fcf-53cdef9b0fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "stemmer = SnowballStemmer(language='english')\n",
    "_re_spec = re.compile(r'([/#\\\\-\\\\.:])')\n",
    "\n",
    "def spec_add_spaces(t):\n",
    "    \"Add spaces around . : - / \\ and #\"\n",
    "    return _re_spec.sub(r' \\1 ', t)\n",
    "\n",
    "# Causes the resulting RE to match from m to n repetitions of the preceding RE, attempting to match as many repetitions as possible.\n",
    "_re_space = re.compile(' {2,}')\n",
    "\n",
    "def rm_useless_spaces(t):\n",
    "    \"Remove multiple spaces\"\n",
    "    return _re_space.sub(' ', t)\n",
    "\n",
    "def transform_name(product_name):\n",
    "    \"Transform product name by replacing punctuations, removing multiple spaces, stemming, lower casing\"\n",
    "    name = product_name\n",
    "\n",
    "    # replace_punct\n",
    "    name = spec_add_spaces(name)\n",
    "    # replace multiple spaces\n",
    "    name = rm_useless_spaces(name)\n",
    "\n",
    "    # add stemmer\n",
    "    name = stemmer.stem(name)\n",
    "    return name.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90fa06f-9cb2-4d51-8705-f6f81513496f",
   "metadata": {},
   "source": [
    "## 1. Sample Rate 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "035ca35f-1ec5-43fc-8f20-e57be2e8c819",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the pruned_products (10% of data) to generate training data\n",
    "!python createContentTrainingData.py --sample_rate 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c7b90a-58b8-4d6c-9e02-12d6b8ea51a5",
   "metadata": {},
   "source": [
    "Output is as follows\n",
    "```\n",
    "Writing results to /workspace/datasets/fasttext/output.fasttext\n",
    "Processing pruned_products_1.xml\n",
    "Processing pruned_products_2.xml\n",
    "Processing pruned_products_3.xml\n",
    "Processing pruned_products_4.xml\n",
    "Processing pruned_products_5.xml\n",
    "Processing pruned_products_6.xml\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5bb46ce-9e58-479f-8990-da9ac2a256bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__label__pcmcat237000050016 DeLorme - inReach 2-Way Satellite Communicator for DeLorme Earthmate PN-60w GPS\n",
      "__label__pcmcat193100050014 Sungale - Beam E-Reader - White\n",
      "__label__pcmcat186400050002 Olympus - X-560WP 10.0-Megapixel Digital Camera - Red\n",
      "__label__pcmcat258900050010 Jura - ENA 9 One Touch Cappuccino and Latte Macchiato Maker - Silver\n",
      "__label__pcmcat258900050010 Jura - Impressa J9 Cappuccino, Latte Macchiato and Caf√© Latte Maker - Silver\n",
      "__label__pcmcat258900050007 Capresso - 10-Cup Coffeemaker - Black/Silver\n",
      "__label__pcmcat174700050005 Mystery Masterpiece: The Moonstone - Windows\n",
      "__label__pcmcat174700050005 Kitchen Brigade - Windows\n",
      "__label__pcmcat158900050018 3M - Mobile SVGA LCOS Projector\n",
      "__label__cat09000 Best Buy GC - $200 Techno Twinkle Gift Card\n"
     ]
    }
   ],
   "source": [
    "!head /workspace/datasets/fasttext/output.fasttext"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a223e07-1006-401b-aced-baf30bdcbfb1",
   "metadata": {},
   "source": [
    "We can confirm the generated output is in the format suitable for fasttext`__label__<label> <product_name>`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68650d4e-e0a5-4587-a0ec-712671a004c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle the input before train/test split\n",
    "!shuf /workspace/datasets/fasttext/output.fasttext > /workspace/datasets/fasttext/shuf_output.fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb961b44-b7a0-4aaf-8fec-8fcad57a48d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11764 /workspace/datasets/fasttext/shuf_output.fasttext\n"
     ]
    }
   ],
   "source": [
    "!wc -l /workspace/datasets/fasttext/shuf_output.fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4afa085-d9e5-4565-8004-5e4c335aeb3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!head -n 10000 /workspace/datasets/fasttext/shuf_output.fasttext > /workspace/datasets/fasttext/products.train\n",
    "!tail -n 1764 /workspace/datasets/fasttext/shuf_output.fasttext > /workspace/datasets/fasttext/products.test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f841f4a1-6976-4f00-9c4e-6a23efa2a666",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = '/workspace/datasets/fasttext/products.train'\n",
    "test_file = '/workspace/datasets/fasttext/products.test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8bf072ab-9626-4c9c-88ce-3af948bcfb88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_supervised\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mkargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Train a supervised model and return a model object.\n",
       "\n",
       "input must be a filepath. The input text does not need to be tokenized\n",
       "as per the tokenize function, but it must be preprocessed and encoded\n",
       "as UTF-8. You might want to consult standard preprocessing scripts such\n",
       "as tokenizer.perl mentioned here: http://www.statmt.org/wmt07/baseline.html\n",
       "\n",
       "The input file must must contain at least one label per line. For an\n",
       "example consult the example datasets which are part of the fastText\n",
       "repository such as the dataset pulled by classification-example.sh.\n",
       "\u001b[0;31mFile:\u001b[0m      ~/.pyenv/versions/search_with_ml_week3/lib/python3.9/site-packages/fasttext/FastText.py\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ft.train_supervised?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd0d7a19-bdf3-438b-a60c-d3b0093a88df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read 0M words\n",
      "Number of words:  11080\n",
      "Number of labels: 1356\n",
      "Progress: 100.0% words/sec/thread:   12354 lr:  0.000000 avg.loss: 13.697918 ETA:   0h 0m 0s\n"
     ]
    }
   ],
   "source": [
    "model = ft.train_supervised(train_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bcddecd3-efd4-4963-b82c-0c789fe61283",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((#11080) ['-','</s>','for','Black','with','and','Digital','Memory','Case','/'...],\n",
       " (#1356) ['__label__abcat0101001','__label__pcmcat180400050006','__label__abcat0401004','__label__pcmcat247400050000','__label__cat09000','__label__abcat0901005','__label__abcat0905001','__label__pcmcat171900050029','__label__abcat0515028','__label__pcmcat151600050006'...])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print(model.words)\n",
    "#print(model.labels)\n",
    "L(model.words), L(model.labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180c375e-d39b-427b-8767-4710d4cb1880",
   "metadata": {},
   "source": [
    "There are 11080 words present from this 10% of data and around 1356 categories present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "381651b5-c23d-48e6-a626-1a3de65ac1c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('__label__abcat0901005',), array([0.35519338]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict('GE - 11.9 Cu. Ft. Top-Mount Refrigerator - Bisque-on-Bisque')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8302bad1-2e61-4f76-9843-bd20d4661029",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m Evaluate supervised model using file given by path\n",
       "\u001b[0;31mFile:\u001b[0m      ~/.pyenv/versions/search_with_ml_week3/lib/python3.9/site-packages/fasttext/FastText.py\n",
       "\u001b[0;31mType:\u001b[0m      method\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.test?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "395acbb0-309a-452b-bfc8-defd3a15541d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N\t: 1719 \n",
      "P@1\t: 0.147 \n",
      "R@1\t: 0.147\n"
     ]
    }
   ],
   "source": [
    "res = model.test(test_file, k=1);print_res(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6af3af4b-d9be-445f-a5f0-d380c888144d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N\t: 1719 \n",
      "P@1\t: 0.047 \n",
      "R@1\t: 0.237\n"
     ]
    }
   ],
   "source": [
    "res = model.test(test_file, k=5);print_res(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "53ea86a7-78c5-45ab-90d9-0066dbf6e148",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N\t: 1719 \n",
      "P@1\t: 0.028 \n",
      "R@1\t: 0.276\n"
     ]
    }
   ],
   "source": [
    "res = model.test(test_file, k=10);print_res(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29fd07b1-f3d2-474e-bb58-dac16a79121a",
   "metadata": {},
   "source": [
    "As we can see the recall is increasing as we increased but precision is dropping."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a0cbe2-982d-4547-a50c-c5f04b8da3cc",
   "metadata": {},
   "source": [
    "### Increase epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "34c2999e-161c-47e2-b9f0-46d27cb2e3e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read 0M words\n",
      "Number of words:  11080\n",
      "Number of labels: 1356\n",
      "Progress: 100.0% words/sec/thread:   12534 lr:  0.000000 avg.loss:  6.282897 ETA:   0h 0m 0s\n"
     ]
    }
   ],
   "source": [
    "# Reference: https://fasttext.cc/docs/en/options.html\n",
    "model=ft.train_supervised(train_file, epoch=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cb6f8b08-3c42-4a6d-bf45-a6732a5972e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(model.epoch, 25) #uses the epoch specified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ed37db24-4eb4-432e-b747-17a80ee1719d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N\t: 1719 \n",
      "P@1\t: 0.450 \n",
      "R@1\t: 0.450\n",
      "\n",
      "N\t: 1719 \n",
      "P@1\t: 0.131 \n",
      "R@1\t: 0.657\n",
      "\n",
      "N\t: 1719 \n",
      "P@1\t: 0.072 \n",
      "R@1\t: 0.721\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[print_res(model.test(test_file, k)) for k in [1, 5, 10]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf1977ca-76dc-4836-827a-b3c5ffedd548",
   "metadata": {},
   "source": [
    "### Increase lr "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "55c17717-abb5-4e5b-abef-06ebf962c0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default lr\n",
    "test_eq(model.lr, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1dfc7033-8d8a-4d20-b32f-67cb5a8ffe29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read 0M words\n",
      "Number of words:  11080\n",
      "Number of labels: 1356\n",
      "Progress: 100.0% words/sec/thread:   12473 lr:  0.000000 avg.loss:  8.922214 ETA:   0h 0m 0s\n"
     ]
    }
   ],
   "source": [
    "model=ft.train_supervised(train_file, lr=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4ae092b8-2d1f-4d04-88fe-4f0207d34f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(model.epoch, 5) #Default epoch\n",
    "test_eq(model.lr, 0.3) # specified lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "938ad73f-6d58-4860-af01-9f2b0c01b22b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N\t: 1719 \n",
      "P@1\t: 0.350 \n",
      "R@1\t: 0.350\n",
      "\n",
      "N\t: 1719 \n",
      "P@1\t: 0.106 \n",
      "R@1\t: 0.532\n",
      "\n",
      "N\t: 1719 \n",
      "P@1\t: 0.059 \n",
      "R@1\t: 0.585\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[print_res(model.test(test_file, k)) for k in [1, 5, 10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "953cc2eb-3de9-4564-a715-72a625d158b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read 0M words\n",
      "Number of words:  11080\n",
      "Number of labels: 1356\n",
      "Progress: 100.0% words/sec/thread:   12777 lr:  0.000000 avg.loss:  4.663769 ETA:   0h 0m 0s\n"
     ]
    }
   ],
   "source": [
    "model=ft.train_supervised(train_file, lr=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "907b2d1e-e5ae-46d1-b17b-d3f9db78b7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(model.lr, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "07d1e153-5303-4494-901a-a6f11666c3fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N\t: 1719 \n",
      "P@1\t: 0.581 \n",
      "R@1\t: 0.581\n",
      "\n",
      "N\t: 1719 \n",
      "P@1\t: 0.155 \n",
      "R@1\t: 0.776\n",
      "\n",
      "N\t: 1719 \n",
      "P@1\t: 0.082 \n",
      "R@1\t: 0.821\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[print_res(model.test(test_file, k)) for k in [1, 5, 10]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0787a759-dcd4-4ede-884a-97483c95667e",
   "metadata": {},
   "source": [
    "### Introducing bigrams with wordNgrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6bf454eb-4c66-4a3d-a9ba-067b9d8e61a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read 0M words\n",
      "Number of words:  11080\n",
      "Number of labels: 1356\n",
      "Progress: 100.0% words/sec/thread:   12354 lr:  0.000000 avg.loss: 14.612494 ETA:   0h 0m 0s100.1% words/sec/thread:   12355 lr: -0.000056 avg.loss: 14.612494 ETA:   0h 0m 0s\n"
     ]
    }
   ],
   "source": [
    "model = ft.train_supervised(train_file, wordNgrams=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "46006ac7-a06b-489e-b0f8-b4443c347539",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(model.wordNgrams, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b037e9a8-4408-454a-bb71-9ca976267d06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N\t: 1719 \n",
      "P@1\t: 0.056 \n",
      "R@1\t: 0.056\n",
      "\n",
      "N\t: 1719 \n",
      "P@1\t: 0.022 \n",
      "R@1\t: 0.108\n",
      "\n",
      "N\t: 1719 \n",
      "P@1\t: 0.014 \n",
      "R@1\t: 0.144\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[print_res(model.test(test_file, k)) for k in [1, 5, 10]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248c94ee-1087-4aa4-a7c3-d5b923a94f42",
   "metadata": {},
   "source": [
    "### Process name_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fff6a6c9-5537-4a3a-ae6d-274fe28a58b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(train_file) as f: train_data = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "488d2acf-8992-4e72-95ae-57bf0c0c3ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(test_file) as f: test_data = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "5bbe5101-7650-4e1b-9303-9e55c5d6440c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "#_re_spec = re.compile(r'([.\\\\!?,\\'/\\(\\)])')\n",
    "_re_spec = re.compile(r'([/#\\\\-\\\\.:])')\n",
    "\n",
    "def spec_add_spaces(t):\n",
    "    #\"Add spaces around \\!?,'/()\"\n",
    "    \"Add spaces around : - / \\ and #\"\n",
    "    return _re_spec.sub(r' \\1 ', t)\n",
    "\n",
    "# Causes the resulting RE to match from m to n repetitions of the preceding RE, attempting to match as many repetitions as possible.\n",
    "_re_space = re.compile(' {2,}')\n",
    "\n",
    "def rm_useless_spaces(t):\n",
    "    \"Remove multiple spaces\"\n",
    "    return _re_space.sub(' ', t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "9ef06d7e-840a-453a-bc82-d51cfef7a4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(spec_add_spaces(\".nltk\"), ' . nltk')\n",
    "test_eq(spec_add_spaces(\"nltk:\"), 'nltk : ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "18526586-e42e-467d-a102-04b1f86cdd30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "stemmer = SnowballStemmer(language='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "70e7f89e-156b-4d86-b61d-62904f4601d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'star wars: the new droid army - game boy advance\\n'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer.stem('star wars: the new droid army - game boy advance\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "8b35e5e2-1a84-43bc-9038-ee79305c1911",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_name(x:str):\n",
    "    tmp = x.split(' ')\n",
    "    cat, name = tmp[0], ' '.join(tmp[1:])\n",
    "    \n",
    "    # replace_punct\n",
    "    name = spec_add_spaces(name)\n",
    "    # replace multiple spaces\n",
    "    name = rm_useless_spaces(name)\n",
    "    \n",
    "    ## add stemmer\n",
    "    name = stemmer.stem(name)\n",
    "    return f\"{cat} {name.lower()}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "ba69bdac-933c-4cdb-b165-99caf94760c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'__label__pcmcat196500050012 sigma - 120-300mm f / 22-2 . 8 zoom lens for nikon dslr camera'"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_name('__label__pcmcat196500050012 Sigma - 120-300mm f/22-2.8 Zoom Lens for Nikon DSLR Cameras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "891032e0-d3b1-4c18-853a-9c98f516145a",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_train_data = L(train_data).map(process_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "ad0afbd6-e9f0-4c31-9c64-3d59a52d5cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_test_data = L(test_data).map(process_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "9380d183-34b2-4474-958c-c81afa13f0f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/workspace/datasets/fasttext/products.train',\n",
       " '/workspace/datasets/fasttext/products.test')"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_file, test_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "669130ea-33c1-4ccf-969c-a180be513fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/workspace/datasets/fasttext/products_proc.train', 'w') as f: f.writelines(list(processed_train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "1fe71692-d266-4f8a-a2cd-74bd2a6d4d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/workspace/datasets/fasttext/products_proc.test', 'w') as f: f.writelines(list(processed_test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "049a4ccc-af49-49c2-9c47-271817a2be34",
   "metadata": {},
   "source": [
    "#### Train with default fasttext params after tranform_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "aac4500e-9dd0-4a1a-9070-c036d74fdf63",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = '/workspace/datasets/fasttext/products_proc.train'\n",
    "test_file = '/workspace/datasets/fasttext/products_proc.test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "89f8470a-68c5-4045-8686-95ab38891866",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read 0M words\n",
      "Number of words:  9989\n",
      "Number of labels: 1356\n",
      "Progress: 100.0% words/sec/thread:   13529 lr:  0.000000 avg.loss: 13.109398 ETA:   0h 0m 0s\n"
     ]
    }
   ],
   "source": [
    "model = ft.train_supervised(train_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "ab083ab4-57fc-45ac-9de6-1a0ca5eada6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N\t: 1719 \n",
      "P@1\t: 0.138 \n",
      "R@1\t: 0.138\n",
      "\n",
      "N\t: 1719 \n",
      "P@1\t: 0.051 \n",
      "R@1\t: 0.255\n",
      "\n",
      "N\t: 1719 \n",
      "P@1\t: 0.029 \n",
      "R@1\t: 0.289\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[print_res(model.test(test_file, k)) for k in [1, 5, 10]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31db7fe8-ffc9-4db5-961f-b13281bacefa",
   "metadata": {},
   "source": [
    "#### Train with optimized fasttext params after tranform_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "2e1fa611-2703-4f61-84f5-ac9609ce8cde",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read 0M words\n",
      "Number of words:  9989\n",
      "Number of labels: 1356\n",
      "Progress: 100.0% words/sec/thread:   12647 lr:  0.000000 avg.loss:  1.256690 ETA:   0h 0m 0s\n"
     ]
    }
   ],
   "source": [
    "model = ft.train_supervised(train_file, epoch=25, lr=1.0, wordNgrams=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "17f90ff9-10a3-4275-aefb-890f1ed0bc66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N\t: 1719 \n",
      "P@1\t: 0.618 \n",
      "R@1\t: 0.618\n",
      "\n",
      "N\t: 1719 \n",
      "P@1\t: 0.161 \n",
      "R@1\t: 0.805\n",
      "\n",
      "N\t: 1719 \n",
      "P@1\t: 0.085 \n",
      "R@1\t: 0.852\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[print_res(model.test(test_file, k)) for k in [1, 5, 10]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7015f18-16c7-402e-873d-b1e9532b7624",
   "metadata": {},
   "source": [
    "Precision jumped from 0.138 to 0.618"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a95318-6edb-4f38-a068-60a2f1340468",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2. Enforce min N of products per category (Sample Rate 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c86eafe1-f7c9-4f85-9290-4a978c7b2ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import xml.etree.ElementTree as ET\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "30717f80-a5e8-427a-97e6-12ac61c51f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "stemmer = SnowballStemmer(language='english')\n",
    "_re_spec = re.compile(r'([/#\\\\-\\\\.:])')\n",
    "\n",
    "def spec_add_spaces(t):\n",
    "    \"Add spaces around . : - / \\ and #\"\n",
    "    return _re_spec.sub(r' \\1 ', t)\n",
    "\n",
    "# Causes the resulting RE to match from m to n repetitions of the preceding RE, attempting to match as many repetitions as possible.\n",
    "_re_space = re.compile(' {2,}')\n",
    "\n",
    "def rm_useless_spaces(t):\n",
    "    \"Remove multiple spaces\"\n",
    "    return _re_space.sub(' ', t)\n",
    "\n",
    "def transform_name(product_name):\n",
    "    \"Transform product name by replacing punctuations, removing multiple spaces, stemming, lower casing\"\n",
    "    name = product_name\n",
    "\n",
    "    # replace_punct\n",
    "    name = spec_add_spaces(name)\n",
    "    # replace multiple spaces\n",
    "    name = rm_useless_spaces(name)\n",
    "\n",
    "    # add stemmer\n",
    "    name = stemmer.stem(name)\n",
    "    return name.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b36f1254-b2ce-4583-b249-2eabf665b183",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory for product data\n",
    "directory = r'/workspace/search_with_machine_learning_course/data/pruned_products/'\n",
    "output_file = r'/workspace/datasets/fasttext/output.fasttext'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da1c91c5-bab3-402f-acc0-9119fb144b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_rate=1.0\n",
    "\n",
    "items=[]\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith(\".xml\"):\n",
    "        print(\"Processing %s\" % filename)\n",
    "        f = os.path.join(directory, filename)\n",
    "        tree = ET.parse(f)\n",
    "        root = tree.getroot()\n",
    "        for child in root:\n",
    "            if random.random() > sample_rate:\n",
    "                continue\n",
    "            # Check to make sure category name is valid\n",
    "            if (child.find('name') is not None and child.find('name').text is not None and\n",
    "                child.find('categoryPath') is not None and len(child.find('categoryPath')) > 0 and\n",
    "                child.find('categoryPath')[len(child.find('categoryPath')) - 1][0].text is not None):\n",
    "                # Choose last element in categoryPath as the leaf categoryId\n",
    "                cat = child.find('categoryPath')[len(child.find('categoryPath')) - 1][0].text\n",
    "                # Replace newline chars with spaces so fastText doesn't complain\n",
    "                name = child.find('name').text.replace('\\n', ' ')\n",
    "                items.append((cat, transform_name(name)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2406ff10-0faa-4c0e-b6ee-793dd4b69ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(items, columns=['cat', 'name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b0d61607-ee9f-4b61-852f-2226d8392928",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(len(df), 115358)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "903068db-4b4a-48cb-ad08-96290b0d688a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_by_min_products(df, minimum=50):\n",
    "    tmp = pd.DataFrame(df.cat.value_counts())\n",
    "    min_filter = tmp[tmp['cat'] > minimum]\n",
    "    return df[df.cat.isin(min_filter.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b1bfebc5-6283-4c1a-9dfe-4b7755780cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = filter_by_min_products(df, minimum=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d475cbe0-b3cd-41d1-bc01-b8b2a1fb8900",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(len(filtered_df), 92726)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "683336e7-21e7-4d5d-bf82-525009465f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_output(df, output_file = r'/workspace/datasets/fasttext/output.fasttext', minimum=50):\n",
    "    filtered_df = filter_by_min_products(df, minimum)\n",
    "    with open(output_file, 'w') as output:\n",
    "        for _, item in filtered_df.iterrows():\n",
    "            output.write(\"__label__%s %s\\n\" % (item['cat'], item['name']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e143edfb-14af-426e-abe2-0d8135d3b158",
   "metadata": {},
   "source": [
    "### Threshold as 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "61c35919-bbce-4613-9435-b7aeb97670fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_output(df, r'/workspace/datasets/fasttext/output_50.fasttext', 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "ebbc24d6-26fa-4f4a-b6bf-43422ef6b5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "path='/workspace/datasets/fasttext/output_50.fasttext'\n",
    "with open(path) as f: data = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "93c439fc-bf14-4913-9285-70e4d6be4d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(data)\n",
    "train = data[0:int(len(data) * 0.9)]\n",
    "test = data[int(len(data) * 0.9):]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "c8a3f945-f03a-44a4-8033-ab64546e7fbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(83453, 9273)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train), len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "f5090b53-b6b1-4eaf-a149-5ddcc0101d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = '/workspace/datasets/fasttext/products.train'\n",
    "test_file = '/workspace/datasets/fasttext/products.test'\n",
    "with open(train_file, 'w') as f: f.writelines(train)\n",
    "with open(test_file, 'w') as f: f.writelines(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "40b1b7e7-ddcc-4de3-a029-74fdc52d9b46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read 1M words\n",
      "Number of words:  25722\n",
      "Number of labels: 512\n",
      "Progress: 100.0% words/sec/thread:   16468 lr:  0.000000 avg.loss:  0.257775 ETA:   0h 0m 0s 0m42s100.0% words/sec/thread:   16468 lr: -0.000005 avg.loss:  0.257775 ETA:   0h 0m 0s\n"
     ]
    }
   ],
   "source": [
    "#using optimized params with threshold 50\n",
    "model = ft.train_supervised(train_file, epoch=25, lr=1.0, wordNgrams=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "51072ae1-086b-45b1-9421-062cc24ce1d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N\t: 9273 \n",
      "P@1\t: 0.843 \n",
      "R@1\t: 0.843\n",
      "\n",
      "N\t: 9273 \n",
      "P@5\t: 0.195 \n",
      "R@5\t: 0.977\n",
      "\n",
      "N\t: 9273 \n",
      "P@10\t: 0.099 \n",
      "R@10\t: 0.986\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[print_res(model.test(test_file, k), k) for k in [1, 5, 10]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a35b117-ef46-459f-b1ff-1fa82ff5b5d9",
   "metadata": {},
   "source": [
    "### Threshold as 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "98a7624f-c7fe-41cc-9b92-3ef1004b98a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_output(df, r'/workspace/datasets/fasttext/output_100.fasttext', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b61f787b-6218-4270-8c10-0e7e521eaf62",
   "metadata": {},
   "outputs": [],
   "source": [
    "path='/workspace/datasets/fasttext/output_100.fasttext'\n",
    "with open(path) as f: data = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c5110806-d160-4f7d-bb40-b820912d184f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(115358, 74801)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df), len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "636231d7-1fbd-499b-8523-0a9b569a204e",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(data)\n",
    "train = data[0:int(len(data) * 0.9)]\n",
    "test = data[int(len(data) * 0.9):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5f6c52fc-04d6-4f21-92f8-41235302affc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = '/workspace/datasets/fasttext/products.train'\n",
    "test_file = '/workspace/datasets/fasttext/products.test'\n",
    "with open(train_file, 'w') as f: f.writelines(train)\n",
    "with open(test_file, 'w') as f: f.writelines(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8a7eef29-4f6d-434a-b433-3657b8e1dc8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read 0M words\n",
      "Number of words:  21404\n",
      "Number of labels: 262\n",
      "Progress: 100.0% words/sec/thread:   53646 lr:  0.000000 avg.loss:  0.184636 ETA:   0h 0m 0s\n"
     ]
    }
   ],
   "source": [
    "#using optimized params with threshold 100\n",
    "model = ft.train_supervised(train_file, epoch=25, lr=1.0, wordNgrams=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "96871583-923b-4071-8d29-0e2a6860a7d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N\t: 7481 \n",
      "P@1\t: 0.884 \n",
      "R@1\t: 0.884\n",
      "\n",
      "N\t: 7481 \n",
      "P@5\t: 0.197 \n",
      "R@5\t: 0.986\n",
      "\n",
      "N\t: 7481 \n",
      "P@10\t: 0.099 \n",
      "R@10\t: 0.991\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[print_res(model.test(test_file, k), k) for k in [1, 5, 10]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3299dbc-b07b-4462-8f48-124fb618c2db",
   "metadata": {},
   "source": [
    "### Threshold as 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7168247c-c9c7-4ad0-8b7c-a2e4d09367cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_output(df, r'/workspace/datasets/fasttext/output_200.fasttext', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0e43d246-e8f8-4f0b-8c9d-bb1f896925ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "path='/workspace/datasets/fasttext/output_200.fasttext'\n",
    "with open(path) as f: data = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "414f9ed1-4f07-41fc-b299-33e877fc2f99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(115358, 53654)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df), len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "08581b75-3ebf-4ab1-aa0a-64d729206026",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(data)\n",
    "train = data[0:int(len(data) * 0.9)]\n",
    "test = data[int(len(data) * 0.9):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "65a3d36e-39fd-4697-becd-464a5b64bec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = '/workspace/datasets/fasttext/products.train'\n",
    "test_file = '/workspace/datasets/fasttext/products.test'\n",
    "with open(train_file, 'w') as f: f.writelines(train)\n",
    "with open(test_file, 'w') as f: f.writelines(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2873fcfb-2dd7-4b11-91db-3dda44c41de3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read 0M words\n",
      "Number of words:  16045\n",
      "Number of labels: 113\n",
      "Progress: 100.0% words/sec/thread:   82599 lr:  0.000000 avg.loss:  0.112276 ETA:   0h 0m 0s\n"
     ]
    }
   ],
   "source": [
    "#using optimized params with threshold 100\n",
    "model = ft.train_supervised(train_file, epoch=25, lr=1.0, wordNgrams=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d7e6e1b4-441e-41a7-88aa-9ff1ca71f853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N\t: 5366 \n",
      "P@1\t: 0.926 \n",
      "R@1\t: 0.926\n",
      "\n",
      "N\t: 5366 \n",
      "P@5\t: 0.199 \n",
      "R@5\t: 0.994\n",
      "\n",
      "N\t: 5366 \n",
      "P@10\t: 0.100 \n",
      "R@10\t: 0.998\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[print_res(model.test(test_file, k), k) for k in [1, 5, 10]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4399f2eb-796c-4a2f-a599-1099d14b0d57",
   "metadata": {},
   "source": [
    "## 3. Replace leaf category with the ancestors (Sample Rate 1.0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d9f9e36e-74ce-43c7-a77d-1eb110c9148b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import xml.etree.ElementTree as ET\n",
    "from pathlib import Path\n",
    "\n",
    "# Directory for product data\n",
    "directory = r'/workspace/search_with_machine_learning_course/data/pruned_products/'\n",
    "output_file = r'/workspace/datasets/fasttext/output.fasttext'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48abb9c9-9fec-46e3-b670-a97d79d00672",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "# Location for category data\n",
    "categoriesFilename = '/workspace/datasets/product_data/categories/categories_0001_abcat0010000_to_pcmcat99300050000.xml'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb02fcc-bd80-4ec4-9958-603b7ccc0a56",
   "metadata": {
    "tags": []
   },
   "source": [
    "```\n",
    "<categoryPath>\n",
    "            <category>\n",
    "                 <id>cat00000</id>\n",
    "                 <name>Best Buy</name>\n",
    "            </category>\n",
    "            <category>\n",
    "                 <id>abcat0800000</id>\n",
    "                 <name>Mobile Phones</name>\n",
    "            </category>\n",
    "            <category>\n",
    "                 <id>pcmcat209400050001</id>\n",
    "                 <name>All Mobile Phones with Plans</name>\n",
    "            </category>\n",
    "       </categoryPath>\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "64dd8881-10b6-46ff-959e-53d448a1023a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "xml = '''\n",
    "<categoryPath>\n",
    "            <category>\n",
    "                 <id>cat00000</id>\n",
    "                 <name>Best Buy</name>\n",
    "            </category>\n",
    "            <category>\n",
    "                 <id>abcat0800000</id>\n",
    "                 <name>Mobile Phones</name>\n",
    "            </category>\n",
    "            <category>\n",
    "                 <id>pcmcat209400050001</id>\n",
    "                 <name>All Mobile Phones with Plans</name>\n",
    "            </category>\n",
    "       </categoryPath>'''\n",
    "\n",
    "tree = ET.fromstring(xml)\n",
    "\n",
    "names = []\n",
    "cat = ''\n",
    "max_depth = 1\n",
    "for depth, child in enumerate(tree):\n",
    "    parent = cat\n",
    "    cat = child.find('name').text if depth <= max_depth else parent\n",
    "    names.append(cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c30e09aa-14f9-4cdc-9928-c3571ebd5d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(names, ['Best Buy', 'Mobile Phones', 'Mobile Phones'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fa89a27e-24d2-475f-b11b-f2f41969810d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "filenames = [filename for filename in os.listdir(directory) if filename.endswith(\".xml\")]\n",
    "\n",
    "def process_file(filename, sample_rate=1.0, max_depth=None):\n",
    "    \"Replacing the categories with ancestors at max_depth 2 or 3 or\" \n",
    "    items = []\n",
    "    print(\"Processing %s\" % filename)\n",
    "    f = os.path.join(directory, filename)\n",
    "    tree = ET.parse(f)\n",
    "    root = tree.getroot()\n",
    "    for child in root:\n",
    "        if random.random() > sample_rate:\n",
    "            continue\n",
    "        \n",
    "        # Check to make sure category name is valid\n",
    "        cname, ccatPath = child.find('name'), child.find('categoryPath')\n",
    "        \n",
    "        if (not max_depth and\n",
    "            cname is not None and cname.text is not None and\n",
    "            ccatPath is not None and len(ccatPath) > 0 and\n",
    "            ccatPath[len(ccatPath) - 1][0].text is not None):\n",
    "            # Choose last element in categoryPath as the leaf categoryId\n",
    "            cat = ccatPath[len(ccatPath) - 1][0].text\n",
    "            # Replace newline chars with spaces so fastText doesn't complain\n",
    "            name = cname.text.replace('\\n', ' ')\n",
    " \n",
    "        elif (cname is not None and cname.text is not None and\n",
    "            ccatPath is not None and len(ccatPath) > 0):\n",
    "            catStr = ''\n",
    "            categories = []\n",
    "            # replace the leaf categories with ancestors set at max depth\n",
    "            for depth, cchild in enumerate(ccatPath):\n",
    "                parent = catStr\n",
    "                catStr = cchild[0].text if depth <= max_depth else parent\n",
    "                categories.append(catStr)\n",
    "            \n",
    "            # Choose the last element since they are replaced with its ancestors\n",
    "            #print(categories)\n",
    "            cat = categories[-1]\n",
    "            \n",
    "            # Replace newline chars with spaces so fastText doesn't complain\n",
    "            name = cname.text.replace('\\n', ' ')\n",
    "        items.append((cat, transform_name(name)))\n",
    "\n",
    "    return items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "07a80496-645e-463d-86a7-a18cadacc67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "all_items = []\n",
    "\n",
    "for each in filenames:\n",
    "    all_items.extend(process_file(each))\n",
    "\n",
    "## using the leaf categoryId\n",
    "df = pd.DataFrame(all_items, columns=['cat', 'name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a9715f-ced8-4722-815f-2a0bbdc59690",
   "metadata": {},
   "source": [
    "### Ancestors at depth 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "79096f15-71b4-44d6-8ee2-725248161f58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing pruned_products_1.xml\n",
      "Processing pruned_products_2.xml\n",
      "Processing pruned_products_3.xml\n",
      "Processing pruned_products_4.xml\n",
      "Processing pruned_products_5.xml\n",
      "Processing pruned_products_6.xml\n"
     ]
    }
   ],
   "source": [
    "all_items = []\n",
    "\n",
    "for each in filenames:\n",
    "    all_items.extend(process_file(each, max_depth=2))\n",
    "\n",
    "## using the leaf categoryOd\n",
    "df = pd.DataFrame(all_items, columns=['cat', 'name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "dc212a5d-67c7-4da9-8352-f5ff970bb41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_output(df, r'/workspace/datasets/fasttext/output_depth2.fasttext')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "98f0b932-1859-4e6a-90eb-3767b5b7ee07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read 1M words\n",
      "Number of words:  29979\n",
      "Number of labels: 124\n",
      "Progress: 100.0% words/sec/thread:   73803 lr:  0.000000 avg.loss:  0.071780 ETA:   0h 0m 0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N\t: 11445 \n",
      "P@1\t: 0.947 \n",
      "R@1\t: 0.947\n",
      "\n",
      "N\t: 11445 \n",
      "P@5\t: 0.198 \n",
      "R@5\t: 0.991\n",
      "\n",
      "N\t: 11445 \n",
      "P@10\t: 0.099 \n",
      "R@10\t: 0.995\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path='/workspace/datasets/fasttext/output_depth2.fasttext'\n",
    "with open(path) as f: data = f.readlines()\n",
    "\n",
    "random.shuffle(data)\n",
    "train = data[0:int(len(data) * 0.9)]\n",
    "test = data[int(len(data) * 0.9):]\n",
    "\n",
    "train_file = '/workspace/datasets/fasttext/products.train'\n",
    "test_file = '/workspace/datasets/fasttext/products.test'\n",
    "with open(train_file, 'w') as f: f.writelines(train)\n",
    "with open(test_file, 'w') as f: f.writelines(test)\n",
    "\n",
    "#using optimized params with threshold 50\n",
    "model = ft.train_supervised(train_file, epoch=25, lr=1.0, wordNgrams=2)\n",
    "\n",
    "[print_res(model.test(test_file, k), k) for k in [1, 5, 10]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df8940bc-fc8a-4207-ae8b-ebf016726f71",
   "metadata": {},
   "source": [
    "### Ancestors at depth 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "53092aaa-6cef-4bd1-a1d2-21f8dc6ddfe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing pruned_products_1.xml\n",
      "Processing pruned_products_2.xml\n",
      "Processing pruned_products_3.xml\n",
      "Processing pruned_products_4.xml\n",
      "Processing pruned_products_5.xml\n",
      "Processing pruned_products_6.xml\n"
     ]
    }
   ],
   "source": [
    "all_items = []\n",
    "\n",
    "for each in filenames:\n",
    "    all_items.extend(process_file(each, max_depth=3))\n",
    "\n",
    "## using the leaf categoryOd\n",
    "df = pd.DataFrame(all_items, columns=['cat', 'name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f2fb40f8-60fe-49ba-91ab-86c0aee33fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_output(df, r'/workspace/datasets/fasttext/output_depth3.fasttext')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "cc32266e-f8a5-493e-8878-a3d9bf949400",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read 1M words\n",
      "Number of words:  28326\n",
      "Number of labels: 346\n",
      "Progress: 100.0% words/sec/thread:   43070 lr:  0.000000 avg.loss:  0.135904 ETA:   0h 0m 0s 59.0% words/sec/thread:   42863 lr:  0.410221 avg.loss:  0.209755 ETA:   0h 0m18s100.0% words/sec/thread:   43070 lr: -0.000013 avg.loss:  0.135904 ETA:   0h 0m 0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N\t: 10809 \n",
      "P@1\t: 0.920 \n",
      "R@1\t: 0.920\n",
      "\n",
      "N\t: 10809 \n",
      "P@5\t: 0.197 \n",
      "R@5\t: 0.984\n",
      "\n",
      "N\t: 10809 \n",
      "P@10\t: 0.099 \n",
      "R@10\t: 0.990\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path='/workspace/datasets/fasttext/output_depth3.fasttext'\n",
    "with open(path) as f: data = f.readlines()\n",
    "\n",
    "random.shuffle(data)\n",
    "train = data[0:int(len(data) * 0.9)]\n",
    "test = data[int(len(data) * 0.9):]\n",
    "\n",
    "train_file = '/workspace/datasets/fasttext/products.train'\n",
    "test_file = '/workspace/datasets/fasttext/products.test'\n",
    "with open(train_file, 'w') as f: f.writelines(train)\n",
    "with open(test_file, 'w') as f: f.writelines(test)\n",
    "\n",
    "#using optimized params with threshold 50\n",
    "model = ft.train_supervised(train_file, epoch=25, lr=1.0, wordNgrams=2)\n",
    "\n",
    "[print_res(model.test(test_file, k), k) for k in [1, 5, 10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dead2acb-05ac-4a89-83ad-332baa9028e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sml_week3",
   "language": "python",
   "name": "sml_week3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
