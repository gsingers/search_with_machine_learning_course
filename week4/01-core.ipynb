{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3b4454e-83c8-41b5-a4d8-dc5c5a010302",
   "metadata": {},
   "source": [
    "# Level 1: Query Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c1bfc0c-9295-40d9-b047-d1da2c4b32c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastcore.foundation import L\n",
    "from fastcore.basics import *\n",
    "from fastcore.test import *\n",
    "from nbdev.showdoc import show_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a61fffda-2060-4389-a21d-52f4d9dc6391",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "stemmer = SnowballStemmer(language='english')\n",
    "_re_spec = re.compile(r'([/#\\\\-\\\\.:\\'\\\"])')\n",
    "\n",
    "def spec_add_spaces(t):\n",
    "    \"Add spaces around \\\" ' . : - / \\ and #\"\n",
    "    return _re_spec.sub(r' \\1 ', t)\n",
    "\n",
    "# Causes the resulting RE to match from m to n repetitions of the preceding RE, attempting to match as many repetitions as possible.\n",
    "_re_space = re.compile(' {2,}')\n",
    "\n",
    "def rm_useless_spaces(t):\n",
    "    \"Remove multiple spaces\"\n",
    "    return _re_space.sub(' ', t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f8aadb4-cd61-41e7-8e19-e7ce2ebaa979",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(spec_add_spaces(\".nltk\"), ' . nltk')\n",
    "test_eq(spec_add_spaces(\"nltk:\"), 'nltk : ')\n",
    "test_eq(spec_add_spaces(\"nltk'\"), \"nltk ' \")\n",
    "test_eq(spec_add_spaces(\"nltk\\\"\"), 'nltk \" ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf424ff-575c-436c-b869-54338583c425",
   "metadata": {},
   "source": [
    "# Prune the Category Taxonomy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a36c40f-a4c3-44e8-8062-5caa1570853b",
   "metadata": {},
   "source": [
    "## Transform Queries\n",
    "\n",
    "Convert the queries to lowercase, strip quotation marks (and perhaps other punctuation), and optionally implement other normalization, like using the nltk stemmer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6d36948-d158-429c-9b30-2d4fdb1c8dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rm_punct(t):\n",
    "    for p in string.punctuation:\n",
    "        t = t.replace(p, ' ')\n",
    "    return t\n",
    "\n",
    "def transform(query):\n",
    "    \"Transform query by replacing punctuations, removing multiple spaces, stemming, lower casing\"\n",
    "    \n",
    "    # replace_punct\n",
    "    query = spec_add_spaces(query)\n",
    "    \n",
    "    # remove punct\n",
    "    query = rm_punct(query)\n",
    "    \n",
    "    # replace multiple spaces\n",
    "    query = rm_useless_spaces(query)\n",
    "    \n",
    "    # fix registered, trademark, copyright symbol\n",
    "    # remove non-ascii characters from query\n",
    "    query = query.encode(encoding='ascii', errors='ignore').decode()\n",
    "    \n",
    "    query = ' '.join([o for o in query.split(' ') if not o.isnumeric()])\n",
    "    \n",
    "    # add stemmer\n",
    "    query = stemmer.stem(query)\n",
    "    return query.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1bee1f2f-9b77-4fd2-a057-07417f24bfa3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "# Useful if you want to perform stemming.\n",
    "import nltk\n",
    "stemmer = nltk.stem.PorterStemmer()\n",
    "\n",
    "categories_file_name = r'/workspace/datasets/product_data/categories/categories_0001_abcat0010000_to_pcmcat99300050000.xml'\n",
    "\n",
    "queries_file_name = r'/workspace/datasets/train.csv'\n",
    "output_file_name = r'/workspace/datasets/labeled_query_data.txt'\n",
    "\n",
    "# parser = argparse.ArgumentParser(description='Process arguments.')\n",
    "# general = parser.add_argument_group(\"general\")\n",
    "# general.add_argument(\"--min_queries\", default=1,  help=\"The minimum number of queries per category label (default is 1)\")\n",
    "# general.add_argument(\"--output\", default=output_file_name, help=\"the file to output to\")\n",
    "\n",
    "# args = parser.parse_args()\n",
    "# output_file_name = args.output\n",
    "\n",
    "# if args.min_queries:\n",
    "#     min_queries = int(args.min_queries)\n",
    "# The root category, named Best Buy with id cat00000, doesn't have a parent.\n",
    "root_category_id = 'cat00000'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af32d450-2664-4a45-862e-1b18f44d7b60",
   "metadata": {},
   "source": [
    "Read the category tree from the categories XML file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "249fa89b-0906-4484-962d-8b639cda9ba6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tree = ET.parse(categories_file_name)\n",
    "root = tree.getroot()\n",
    "\n",
    "# Parse the category XML file to map each category id to its parent category id in a dataframe.\n",
    "categories = []\n",
    "parents = []\n",
    "for child in root:\n",
    "    id = child.find('id').text\n",
    "    cat_path = child.find('path')\n",
    "    cat_path_ids = [cat.find('id').text for cat in cat_path]\n",
    "    leaf_id = cat_path_ids[-1]\n",
    "    if leaf_id != root_category_id:\n",
    "        categories.append(leaf_id)\n",
    "        parents.append(cat_path_ids[-2])\n",
    "parents_df = pd.DataFrame(list(zip(categories, parents)), columns =['category', 'parent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7dc41c0a-a31c-481e-bc2f-e07c043e6ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the training data into pandas, only keeping queries with non-root categories in our category tree.\n",
    "df = pd.read_csv(queries_file_name)[['category', 'query']]\n",
    "df = df[df['category'].isin(categories)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b2e3d41-418f-4a13-8cbf-a3eafb94aac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPLEMENTED: Convert queries to lowercase, and optionally implement other normalization, like stemming.\n",
    "df['query'] = df['query'].apply(transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3311b311-875f-49d9-92ec-8ecb9923e556",
   "metadata": {},
   "source": [
    "## Query Count of Leaf Categories\n",
    "\n",
    "Compute the query count of all leaf categories.\n",
    "\n",
    "What is leaf? \n",
    "A category that is not a parent. So it cannot exist in the parent column. For each category check if exists in parent column, then update is_leaf value for that row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b87de8c3-eeb6-47c5-aa0e-d1e973299c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(len(parents_df), 4639)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "34ede4d8-4f0c-43cd-9c6e-fb20f80b878d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(root_category_id in parents_df.values, True)\n",
    "test_eq(root_category_id in categories, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b5c97a5c-4000-49c0-9749-b86ff56f3deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "parents_df['is_leaf'] = ~parents_df.category.isin(parents_df.parent)\n",
    "parents_df['roll_up'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "797b22c0-f974-4ab1-876f-cdeb8d67b883",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parent(cat):\n",
    "    if cat in parents_df.category.values:\n",
    "        return parents_df[parents_df.category == cat ].parent.to_list()[0]\n",
    "    else:\n",
    "        return root_category_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "224d430c-1c77-4d2f-8c33-0bc6af4af4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "aleaf = parents_df[parents_df.is_leaf].category.values[0] # 'abcat0011001'\n",
    "test_eq(len(parents_df[parents_df.parent == aleaf]), 0)\n",
    "\n",
    "expected = 'abcat0011000'\n",
    "test_eq(parent('abcat0011003'), expected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0f1420f7-4240-4045-b3ee-d672bfbba294",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accepts a seq of tuple\n",
    "data = L(df.category.value_counts().to_dict().items())\n",
    "qcount = pd.DataFrame.from_records(data, columns=['cat', 'count'])\n",
    "\n",
    "cat_counts = df.category.value_counts().to_dict()\n",
    "\n",
    "# Compute the query counts of all categories from train.csv and 0 if category not present\n",
    "parent_counts = [cat_counts.get(o['category'], 0) for _, o in parents_df.iterrows()]\n",
    "parents_df['counts'] = parent_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b66f1f30-0604-4e74-af8f-2fd34b79b033",
   "metadata": {},
   "source": [
    "## Pruning: Rollup Categories to Min. # of Queries per Category\n",
    "\n",
    "For example, if the minimum number of queries is 100 and there are only 99 queries mapped to “Best Buy > Musical Instruments > Guitars > Bass Guitars”, then those queries would be mapped to parent category “Best Buy > Musical Instruments > Guitars”. If the minimum number of queries were higher (e.g., 1,000), then those queries might have to be rolled up to an even broader category, like ““Best Buy > Musical Instruments”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3e2d7633-8221-4c0e-871d-b049574e07b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "source = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "82dba788-4486-4e59-bfe6-cfde77b54e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_queries=1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "86b6fcce-fa30-400f-bf65-8c8faaa6bed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of Categories before pruning : 1486\n",
      "Categories to be pruned : 232\n",
      "Categories to be pruned : 42\n",
      "Categories to be pruned : 5\n",
      "Categories to be pruned : 1\n",
      "Categories to be pruned : 0\n",
      "\n",
      "# of Categories after pruning : 386\n"
     ]
    }
   ],
   "source": [
    "# IMPLEMENTED: Roll up categories to ancestors to satisfy the minimum number of queries per category.\n",
    "cat_count = df.groupby('category').size().to_frame('count')\n",
    "\n",
    "print(f\"# of Categories before pruning : {len(df.category.value_counts())}\")\n",
    "\n",
    "# categories to be pruned\n",
    "prune_df = cat_count[cat_count['count'] < min_queries];\n",
    "\n",
    "while len(prune_df) > 0:\n",
    "    for cat, count in prune_df.iterrows():\n",
    "        df.replace(to_replace=cat, value=parent(cat), inplace=True)\n",
    "    cat_count = df.groupby('category').size().to_frame('count')\n",
    "    prune_df = cat_count[cat_count['count'] < min_queries]\n",
    "    print(f\"Categories to be pruned : {len(prune_df)}\")\n",
    "    \n",
    "print()\n",
    "print(f\"# of Categories after pruning : {len(df.category.value_counts())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "80d34860-e2e6-47bd-aa3e-2fd16a7f67a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create labels in fastText format.\n",
    "df['label'] = '__label__' + df['category']\n",
    "\n",
    "# Output labeled query data as a space-separated file, making sure that every category is in the taxonomy.\n",
    "df = df[df['category'].isin(categories)]\n",
    "df['output'] = df['label'] + ' ' + df['query']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c7852e44-3a11-4bad-8266-ae7acec076f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['output']].to_csv(output_file_name, header=False, sep='|', escapechar='\\\\', quoting=csv.QUOTE_NONE, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "069e9c74-7939-4bf5-9f2b-de4e8f72065a",
   "metadata": {},
   "source": [
    "# fin"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sml_week4",
   "language": "python",
   "name": "sml_week4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc-autonumbering": true,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
